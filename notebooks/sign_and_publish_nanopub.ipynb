{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanopublication Signer & Publisher\n",
    "\n",
    "Signs and publishes nanopublication `.trig` files to the Nanopub network via Nanodash.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Install the nanopub library**: `pip install nanopub`\n",
    "2. **Set up your profile**: Run `np setup` in terminal to create your ORCID-linked profile\n",
    "3. **Have `.trig` files ready**: Generated from the nanopub generator notebooks\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. **Set input path(s)** in Section 1 (single file or directory)\n",
    "2. **Configure options** (test server, auto-publish)\n",
    "3. **Run All Cells** ‚Üí Get signed & published nanopubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìÅ SECTION 1: INPUT CONFIGURATION (EDIT THIS)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# OPTION A: Single .trig file\n",
    "# ============================================\n",
    "\n",
    "#INPUT_FILE = \"../output/superseding/aida_qomic_01_superseding.trig\"\n",
    "#INPUT_FILE = \"../output/superseding/aida_qomic_02_superseding.trig\"\n",
    "#INPUT_FILE = \"../output/superseding/aida_qomic_03_superseding.trig\"\n",
    "#INPUT_FILE = \"../output/superseding/aida_qomic_04_superseding.trig\"\n",
    "\n",
    "#INPUT_FILE = \"../output/aida/aida_clenet_01.trig\"\n",
    "#INPUT_FILE = \"../output/superseding/aida_clenet_01_superseding.trig\"\n",
    "#INPUT_FILE = \"../output/aida/aida_clenet_06.trig\"\n",
    "\n",
    "#INPUT_FILE = \"../output/cito/cito_qomic_trrust.trig\"\n",
    "#INPUT_FILE = \"../output/cito/cito_qomic_qaoa.trig\"\n",
    "#INPUT_FILE = \"../output/cito/cito_qomic_motif.trig\"\n",
    "#INPUT_FILE = \"../output/cito/cito_qomic_qiskit.trig\"\n",
    "\n",
    "\n",
    "#INPUT_FILE = \"../output/cito/cito_qomic_qiskit.trig\"\n",
    "\n",
    "#INPUT_FILE = \"../output/cito/cito_qomic_qiskit.trig\"\n",
    "\n",
    "#INPUT_FILE = \"../output/cito/cito_clenet_carleman.trig\"\t\t\n",
    "#INPUT_FILE = \"../output/cito/cito_clenet_montanaro_mc.trig\"\t\n",
    "#INPUT_FILE = \"../output/cito/cito_clenet_qlsa.trig\"\n",
    "#INPUT_FILE = \"../output/cito/cito_clenet_grover.trig\"\t\t\n",
    "#INPUT_FILE = \"../output/cito/cito_clenet_qaoa.trig\"\t\t\n",
    "#INPUT_FILE = \"../output/cito/cito_clenet_woolnough.trig\"\n",
    "\n",
    "\n",
    "#INPUT_FILE = \"../output/comment/comment_qomic_performance.trig\"\n",
    "#INPUT_FILE = \"../output/comment/comment_qomic_scalability.trig\"\n",
    "#INPUT_FILE = \"../output/comment/comment_qomic_diseases.trig\"\n",
    "\n",
    "\n",
    "#INPUT_FILE = \"../output/comment/comment_clenet_impact.trig\"\t\n",
    "#INPUT_FILE = \"../output/superseding/comment_clenet_superseding_v2.trig\"\n",
    "#INPUT_FILE = \"../output/comment/comment_clenet_nisq.trig\"\n",
    "#INPUT_FILE = \"../output/comment/comment_clenet_limitation.trig\"\t\n",
    "#INPUT_FILE = \"../output/comment/comment_clenet_speedup.trig\"\n",
    "\n",
    "\n",
    "#INPUT_FILE = \"../output/wikidata/wikidata_paper_subject_motif.trig\"\t\n",
    "#INPUT_FILE = \"../output/wikidata/wikidata_qomic_instance.trig\"\t\t\n",
    "#INPUT_FILE = \"../output/wikidata/wikidata_qomic_uses_qiskit.trig\"\n",
    "#INPUT_FILE = \"../output/wikidata/wikidata_paper_subject_quantum.trig\"\t\n",
    "#INPUT_FILE = \"../output/wikidata/wikidata_qiskit_instance.trig\"\n",
    "\n",
    "#INPUT_FILE = \"../output/wikidata/wikidata_clenet_subject_ecology.trig\"\t\n",
    "#INPUT_FILE = \"../output/wikidata/wikidata_clenet_subject_networks.trig\"\n",
    "#INPUT_FILE = \"../output/wikidata/wikidata_clenet_subject_ecomodel.trig\"\t\n",
    "#INPUT_FILE = \"../output/wikidata/wikidata_clenet_subject_qc.trig\"\n",
    "\n",
    "#INPUT_FILE = \"../output/software/software_qiskit.trig\"\n",
    "#INPUT_FILE = \"../output/software/software_qomic.trig\"\n",
    "\n",
    "#INPUT_FILE = \"../output/dataset/dataset_qomic_synthetic.trig\"\n",
    "#INPUT_FILE = \"../output/dataset/dataset_trrust.trig\"\n",
    "\n",
    "INPUT_FILE = \"../output/superseding/dataset_qomic_synthetic_superseding.trig\"\n",
    "\n",
    "# ============================================\n",
    "# OPTION B: Directory of .trig files (processes all)\n",
    "# ============================================\n",
    "# INPUT_FILE = \"../output/aida/\"  # All .trig files in directory\n",
    "\n",
    "# ============================================\n",
    "# OPTION C: List of specific files\n",
    "# ============================================\n",
    "# INPUT_FILE = [\n",
    "#     \"../output/aida/aida_qomic_01.trig\",\n",
    "#     \"../output/software/software_qomic.trig\",\n",
    "#     \"../output/cito/cito_qomic_trrust.trig\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PUBLISHING OPTIONS\n",
    "# ============================================\n",
    "\n",
    "# Set to True to actually publish (False = sign only)\n",
    "PUBLISH = True\n",
    "\n",
    "# Set to True to use test server (for testing, won't be on main network)\n",
    "USE_TEST_SERVER = False\n",
    "\n",
    "# Output directory for signed files (None = same as input)\n",
    "OUTPUT_DIR = None  # e.g., \"../output/signed/\"\n",
    "\n",
    "# Skip files that have already been signed (check for .signed.trig)\n",
    "SKIP_ALREADY_SIGNED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ‚öôÔ∏è SECTION 2: SETUP\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# !pip install nanopub rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading nanopub library...\n",
      "‚úì nanopub library loaded\n",
      "\n",
      "‚úì Setup complete\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "print(\"Loading nanopub library...\")\n",
    "try:\n",
    "    from nanopub import Nanopub, NanopubConf, load_profile\n",
    "    print(\"‚úì nanopub library loaded\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå nanopub library not found\")\n",
    "    print(\"   Install with: pip install nanopub\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n‚úì Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üë§ SECTION 3: LOAD PROFILE\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading nanopub profile...\n",
      "‚úì Profile loaded\n",
      "  Name:  Anne Fouilloux\n",
      "  ORCID: https://orcid.org/0000-0002-1784-2920\n"
     ]
    }
   ],
   "source": [
    "# Load your nanopub profile\n",
    "print(\"Loading nanopub profile...\")\n",
    "try:\n",
    "    profile = load_profile()\n",
    "    print(f\"‚úì Profile loaded\")\n",
    "    print(f\"  Name:  {profile.name}\")\n",
    "    print(f\"  ORCID: {profile.orcid_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load profile: {e}\")\n",
    "    print(\"\\nTo create a profile, run in terminal:\")\n",
    "    print(\"  np setup\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration ready (Server: PRODUCTION)\n"
     ]
    }
   ],
   "source": [
    "# Create configuration\n",
    "conf = NanopubConf(\n",
    "    profile=profile,\n",
    "    use_test_server=USE_TEST_SERVER\n",
    ")\n",
    "\n",
    "server_type = \"TEST\" if USE_TEST_SERVER else \"PRODUCTION\"\n",
    "print(f\"‚úì Configuration ready (Server: {server_type})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìÇ SECTION 4: COLLECT INPUT FILES\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Found 1 .trig file(s):\n",
      "   ‚Ä¢ ../output/superseding/dataset_qomic_synthetic_superseding.trig\n"
     ]
    }
   ],
   "source": [
    "def collect_trig_files(input_spec):\n",
    "    \"\"\"\n",
    "    Collect .trig files from various input specifications.\n",
    "    \n",
    "    Args:\n",
    "        input_spec: Can be:\n",
    "            - str: Path to single file or directory\n",
    "            - list: List of file paths\n",
    "            - Path: Path object\n",
    "    \n",
    "    Returns:\n",
    "        List of Path objects to .trig files\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    \n",
    "    if isinstance(input_spec, list):\n",
    "        # List of files\n",
    "        for f in input_spec:\n",
    "            p = Path(f)\n",
    "            if p.exists() and p.suffix == '.trig':\n",
    "                files.append(p)\n",
    "            else:\n",
    "                print(f\"‚ö† Skipping (not found or not .trig): {f}\")\n",
    "    else:\n",
    "        path = Path(input_spec)\n",
    "        if path.is_file():\n",
    "            # Single file\n",
    "            if path.suffix == '.trig':\n",
    "                files.append(path)\n",
    "            else:\n",
    "                print(f\"‚ö† Not a .trig file: {path}\")\n",
    "        elif path.is_dir():\n",
    "            # Directory - find all .trig files\n",
    "            files = list(path.glob(\"*.trig\"))\n",
    "            # Exclude already signed files\n",
    "            files = [f for f in files if not f.stem.endswith('.signed')]\n",
    "        else:\n",
    "            print(f\"‚ùå Path not found: {path}\")\n",
    "    \n",
    "    return sorted(files)\n",
    "\n",
    "\n",
    "# Collect files\n",
    "trig_files = collect_trig_files(INPUT_FILE)\n",
    "\n",
    "if not trig_files:\n",
    "    print(\"‚ùå No .trig files found!\")\n",
    "    print(f\"   Input: {INPUT_FILE}\")\n",
    "else:\n",
    "    print(f\"‚úì Found {len(trig_files)} .trig file(s):\")\n",
    "    for f in trig_files:\n",
    "        print(f\"   ‚Ä¢ {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Files to process: 1\n"
     ]
    }
   ],
   "source": [
    "# Filter out already signed files if requested\n",
    "if SKIP_ALREADY_SIGNED:\n",
    "    original_count = len(trig_files)\n",
    "    \n",
    "    def has_signed_version(f):\n",
    "        signed_path = f.parent / f\"{f.stem}.signed.trig\"\n",
    "        return signed_path.exists()\n",
    "    \n",
    "    trig_files = [f for f in trig_files if not has_signed_version(f)]\n",
    "    \n",
    "    skipped = original_count - len(trig_files)\n",
    "    if skipped > 0:\n",
    "        print(f\"‚Ñπ Skipped {skipped} already-signed file(s)\")\n",
    "\n",
    "print(f\"\\nüìã Files to process: {len(trig_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üîè SECTION 5: SIGN & PUBLISH\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_and_publish(trig_path, conf, publish=True, output_dir=None):\n",
    "    \"\"\"\n",
    "    Sign and optionally publish a single nanopublication.\n",
    "    \n",
    "    Args:\n",
    "        trig_path: Path to the .trig file\n",
    "        conf: NanopubConf configuration\n",
    "        publish: Whether to publish after signing\n",
    "        output_dir: Directory for signed file (None = same as input)\n",
    "    \n",
    "    Returns:\n",
    "        dict with results\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'input': str(trig_path),\n",
    "        'signed_path': None,\n",
    "        'published_uri': None,\n",
    "        'success': False,\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Load the nanopub\n",
    "        np_obj = Nanopub(rdf=trig_path, conf=conf)\n",
    "        \n",
    "        # Sign it\n",
    "        np_obj.sign()\n",
    "        \n",
    "        # Determine output path\n",
    "        if output_dir:\n",
    "            out_dir = Path(output_dir)\n",
    "            out_dir.mkdir(parents=True, exist_ok=True)\n",
    "            signed_path = out_dir / f\"{trig_path.stem}.signed.trig\"\n",
    "        else:\n",
    "            signed_path = trig_path.parent / f\"{trig_path.stem}.signed.trig\"\n",
    "        \n",
    "        # Save signed version\n",
    "        np_obj.store(signed_path)\n",
    "        result['signed_path'] = str(signed_path)\n",
    "        \n",
    "        # Publish if requested\n",
    "        if publish:\n",
    "            np_obj.publish()\n",
    "            result['published_uri'] = np_obj.source_uri\n",
    "        \n",
    "        result['success'] = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        result['error'] = str(e)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PROCESSING 1 NANOPUBLICATION(S)\n",
      "Mode: SIGN + PUBLISH\n",
      "Server: PRODUCTION\n",
      "======================================================================\n",
      "\n",
      "[1/1] Processing: dataset_qomic_synthetic_superseding.trig\n",
      "    ‚úì Signed: ../output/superseding/dataset_qomic_synthetic_superseding.signed.trig\n",
      "    ‚úì Published: https://w3id.org/np/RAhVkKsOBlENUPLJHnLO-CGtkwkAWFzLo0JbH179ilpEk\n",
      "\n",
      "======================================================================\n",
      "COMPLETE: 1 succeeded, 0 failed\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Process all files\n",
    "results = []\n",
    "success_count = 0\n",
    "fail_count = 0\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"PROCESSING {len(trig_files)} NANOPUBLICATION(S)\")\n",
    "print(f\"Mode: {'SIGN + PUBLISH' if PUBLISH else 'SIGN ONLY'}\")\n",
    "print(f\"Server: {'TEST' if USE_TEST_SERVER else 'PRODUCTION'}\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "for i, trig_file in enumerate(trig_files, 1):\n",
    "    print(f\"[{i}/{len(trig_files)}] Processing: {trig_file.name}\")\n",
    "    \n",
    "    result = sign_and_publish(\n",
    "        trig_path=trig_file,\n",
    "        conf=conf,\n",
    "        publish=PUBLISH,\n",
    "        output_dir=OUTPUT_DIR\n",
    "    )\n",
    "    results.append(result)\n",
    "    \n",
    "    if result['success']:\n",
    "        success_count += 1\n",
    "        print(f\"    ‚úì Signed: {result['signed_path']}\")\n",
    "        if result['published_uri']:\n",
    "            print(f\"    ‚úì Published: {result['published_uri']}\")\n",
    "    else:\n",
    "        fail_count += 1\n",
    "        print(f\"    ‚ùå Error: {result['error']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"COMPLETE: {success_count} succeeded, {fail_count} failed\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìä SECTION 6: RESULTS SUMMARY\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results table\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'File':<40} {'Status':<10} {'URI/Error'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for r in results:\n",
    "    filename = Path(r['input']).name[:38]\n",
    "    if r['success']:\n",
    "        status = \"‚úì OK\"\n",
    "        detail = r['published_uri'] or \"(signed only)\"\n",
    "    else:\n",
    "        status = \"‚ùå FAIL\"\n",
    "        detail = r['error'][:40] if r['error'] else \"Unknown error\"\n",
    "    \n",
    "    print(f\"{filename:<40} {status:<10} {detail}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export published URIs\n",
    "published_uris = [\n",
    "    {\n",
    "        'file': Path(r['input']).name,\n",
    "        'uri': r['published_uri']\n",
    "    }\n",
    "    for r in results\n",
    "    if r['success'] and r['published_uri']\n",
    "]\n",
    "\n",
    "if published_uris:\n",
    "    print(\"\\nüìã PUBLISHED NANOPUBLICATION URIs:\")\n",
    "    print(\"-\" * 70)\n",
    "    for item in published_uris:\n",
    "        print(f\"‚Ä¢ {item['file']}\")\n",
    "        print(f\"  {item['uri']}\")\n",
    "    \n",
    "    # Save to JSON\n",
    "    output_json = Path(OUTPUT_DIR or \".\") / \"published_nanopubs.json\"\n",
    "    with open(output_json, 'w') as f:\n",
    "        json.dump({\n",
    "            'published_at': datetime.now().isoformat(),\n",
    "            'server': 'test' if USE_TEST_SERVER else 'production',\n",
    "            'publisher': profile.name,\n",
    "            'orcid': profile.orcid_id,\n",
    "            'nanopublications': published_uris\n",
    "        }, f, indent=2)\n",
    "    print(f\"\\n‚úì URIs saved to: {output_json}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üîç SECTION 7: VERIFY PUBLICATION (OPTIONAL)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify a published nanopub by fetching it\n",
    "VERIFY_URI = None  # Set to a published URI to verify, e.g.:\n",
    "# VERIFY_URI = \"https://w3id.org/np/RAxxxxxxxxx\"\n",
    "\n",
    "if VERIFY_URI:\n",
    "    print(f\"Verifying: {VERIFY_URI}\")\n",
    "    try:\n",
    "        from nanopub import Nanopub\n",
    "        fetched = Nanopub(source_uri=VERIFY_URI)\n",
    "        print(\"‚úì Nanopub successfully retrieved!\")\n",
    "        print(f\"  Label: {fetched.rdf.value(fetched.assertion, RDFS.label)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Verification failed: {e}\")\n",
    "elif published_uris:\n",
    "    # Auto-verify first published nanopub\n",
    "    first_uri = published_uris[0]['uri']\n",
    "    print(f\"Auto-verifying first publication: {first_uri}\")\n",
    "    try:\n",
    "        from nanopub import Nanopub\n",
    "        fetched = Nanopub(source_uri=first_uri)\n",
    "        print(\"‚úì Nanopub successfully retrieved from network!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† Could not verify (may need time to propagate): {e}\")\n",
    "else:\n",
    "    print(\"‚Ñπ No nanopubs to verify\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìñ USAGE GUIDE\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "```python\n",
    "# Single file\n",
    "INPUT_FILE = \"path/to/nanopub.trig\"\n",
    "\n",
    "# All files in directory\n",
    "INPUT_FILE = \"path/to/output/aida/\"\n",
    "\n",
    "# Specific files\n",
    "INPUT_FILE = [\n",
    "    \"output/aida/aida_01.trig\",\n",
    "    \"output/software/software_01.trig\"\n",
    "]\n",
    "```\n",
    "\n",
    "## Options\n",
    "\n",
    "| Option | Default | Description |\n",
    "|--------|---------|-------------|\n",
    "| `PUBLISH` | `True` | Publish after signing |\n",
    "| `USE_TEST_SERVER` | `False` | Use test network |\n",
    "| `OUTPUT_DIR` | `None` | Custom output directory |\n",
    "| `SKIP_ALREADY_SIGNED` | `True` | Skip files with existing .signed.trig |\n",
    "\n",
    "## Profile Setup\n",
    "\n",
    "If you haven't set up a nanopub profile:\n",
    "\n",
    "```bash\n",
    "# In terminal\n",
    "np setup\n",
    "```\n",
    "\n",
    "This will:\n",
    "1. Create RSA keys for signing\n",
    "2. Link to your ORCID\n",
    "3. Store profile in `~/.nanopub/profile.yml`\n",
    "\n",
    "## Batch Publishing Workflow\n",
    "\n",
    "1. Generate nanopubs with the generator notebooks\n",
    "2. Set `INPUT_FILE = \"../output/\"` to process all subdirectories\n",
    "3. Run this notebook to sign & publish all at once\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
