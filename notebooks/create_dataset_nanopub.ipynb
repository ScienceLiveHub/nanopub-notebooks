{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Nanopublication Generator\n",
    "\n",
    "This notebook generates nanopublications for datasets from a JSON configuration file.\n",
    "\n",
    "## Dataset Nanopublications\n",
    "Dataset nanopublications describe research datasets following FAIR principles, including:\n",
    "- Dataset identification and description\n",
    "- Access URLs and formats\n",
    "- Licensing and attribution\n",
    "- Domain and language metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from nanopub_utils import (\n",
    "    NanopubGenerator, load_config, save_nanopub,\n",
    "    make_uri, make_literal, validate_required_fields,\n",
    "    generate_nanopub_uri, PREFIXES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetNanopubGenerator(NanopubGenerator):\n",
    "    \"\"\"Generator for dataset nanopublications.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: dict, nanopub_config: dict):\n",
    "        # Merge metadata with individual nanopub config\n",
    "        merged_config = {\n",
    "            **config.get('metadata', {}),\n",
    "            **nanopub_config,\n",
    "            'template_uri': config.get('template_uri'),\n",
    "            'label': nanopub_config.get('nanopub_label', nanopub_config.get('label', 'Dataset'))\n",
    "        }\n",
    "        super().__init__(merged_config)\n",
    "        self.add_prefix('fdof')\n",
    "        self.add_prefix('fair')\n",
    "        self.add_prefix('dcat')\n",
    "        self.add_prefix('schema')\n",
    "    \n",
    "    def generate_assertion(self) -> str:\n",
    "        \"\"\"Generate the dataset assertion graph.\"\"\"\n",
    "        # Get dataset URI or generate local one\n",
    "        dataset_uri = self.config.get('dataset_uri')\n",
    "        if not dataset_uri:\n",
    "            dataset_uri = f\"{self.nanopub_uri}#dataset\"\n",
    "        \n",
    "        label = self.config.get('label', 'Unnamed Dataset')\n",
    "        description = self.config.get('description', '')\n",
    "        access_url = self.config.get('access_url')\n",
    "        format_type = self.config.get('format')\n",
    "        license_uri = self.config.get('license_uri')\n",
    "        domain = self.config.get('domain')\n",
    "        language = self.config.get('language')\n",
    "        creators = self.config.get('creators', [])\n",
    "        version = self.config.get('version')\n",
    "        related_pub = self.config.get('related_publication')\n",
    "        \n",
    "        lines = [f\"{self.sub_prefix}:assertion {{\"]\n",
    "        \n",
    "        # Declare the dataset as FAIR Digital Object\n",
    "        lines.append(f\"  <{dataset_uri}> a fdof:FAIRDigitalObject ;\")\n",
    "        lines.append(f\"    a <https://w3id.org/fair/ff/terms/Dataset> ;\")\n",
    "        lines.append(f\"    rdfs:label {make_literal(label)} .\")\n",
    "        \n",
    "        # Add description\n",
    "        if description:\n",
    "            lines.append(f\"  <{dataset_uri}> rdfs:comment {make_literal(description)} .\")\n",
    "        \n",
    "        # Add access URL\n",
    "        if access_url:\n",
    "            lines.append(f\"  <{dataset_uri}> dcat:accessURL <{access_url}> .\")\n",
    "        \n",
    "        # Add format\n",
    "        if format_type:\n",
    "            lines.append(f\"  <{dataset_uri}> fdof:hasEncodingFormat {make_literal(format_type)} .\")\n",
    "        \n",
    "        # Add license\n",
    "        if license_uri:\n",
    "            lines.append(f\"  <{dataset_uri}> dct:license <{license_uri}> .\")\n",
    "        \n",
    "        # Add domain/subject\n",
    "        if domain:\n",
    "            lines.append(f\"  <{dataset_uri}> dct:subject {make_literal(domain)} .\")\n",
    "        \n",
    "        # Add language\n",
    "        if language:\n",
    "            lines.append(f\"  <{dataset_uri}> dct:language {make_literal(language)} .\")\n",
    "        \n",
    "        # Add creators\n",
    "        for creator in creators:\n",
    "            if creator.get('orcid'):\n",
    "                orcid = creator['orcid']\n",
    "                lines.append(f\"  <{dataset_uri}> dct:creator orcid:{orcid} .\")\n",
    "                if creator.get('name'):\n",
    "                    lines.append(f\"  orcid:{orcid} foaf:name {make_literal(creator['name'])} .\")\n",
    "        \n",
    "        # Add version\n",
    "        if version:\n",
    "            lines.append(f\"  <{dataset_uri}> dct:hasVersion {make_literal(version)} .\")\n",
    "        \n",
    "        # Add related publication\n",
    "        if related_pub:\n",
    "            pub_uri = related_pub if related_pub.startswith('http') else f\"https://doi.org/{related_pub}\"\n",
    "            lines.append(f\"  <{dataset_uri}> dct:isReferencedBy <{pub_uri}> .\")\n",
    "        \n",
    "        # Add metadata reference to this nanopub\n",
    "        lines.append(f\"  <{dataset_uri}> fdof:hasMetadata this: .\")\n",
    "        \n",
    "        lines.append(\"}\")\n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG_FILE = \"../config/vbae208_dataset.json\"  # Change this to use different config\n",
    "OUTPUT_DIR = \"../output/dataset\"\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config(CONFIG_FILE)\n",
    "\n",
    "print(f\"Source paper: {config['metadata']['source_paper']['title']}\")\n",
    "print(f\"DOI: {config['metadata']['source_paper']['doi']}\")\n",
    "print(f\"Number of dataset nanopublications to generate: {len(config['nanopublications'])}\")\n",
    "print()\n",
    "\n",
    "for i, np_config in enumerate(config['nanopublications'], 1):\n",
    "    print(f\"{i}. {np_config['label']}\")\n",
    "    print(f\"   Access URL: {np_config.get('access_url', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate nanopublications\n",
    "generated_files = []\n",
    "\n",
    "for np_config in config['nanopublications']:\n",
    "    # Create generator\n",
    "    generator = DatasetNanopubGenerator(config, np_config)\n",
    "    \n",
    "    # Generate nanopub content\n",
    "    nanopub_content = generator.generate()\n",
    "    \n",
    "    # Save to file\n",
    "    output_file = f\"{OUTPUT_DIR}/{np_config['id']}.trig\"\n",
    "    save_nanopub(nanopub_content, output_file)\n",
    "    generated_files.append(output_file)\n",
    "    \n",
    "    print(f\"Generated: {output_file}\")\n",
    "\n",
    "print(f\"\\nTotal generated: {len(generated_files)} nanopublications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview first generated nanopublication\n",
    "if generated_files:\n",
    "    print(f\"Preview of {generated_files[0]}:\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    with open(generated_files[0], 'r') as f:\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Review the generated `.trig` files in the output directory\n",
    "2. Sign and publish using Nanodash or nanopub-java\n",
    "3. To use with a different paper, create a new JSON config file and update `CONFIG_FILE`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
